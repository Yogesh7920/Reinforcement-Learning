{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RL Assignment - 1\n",
    "## _Two state toy problem_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. How many policies are possible ?. Enumerate the policies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Answer*\n",
    "There are 4 possible policies:\n",
    "- S1 - Left and S2 - Left\n",
    "- S1 - Left and S2 - Right\n",
    "- S1 - Right and S2 - Right\n",
    "- S1 - Right and S2 - Right\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "P = [\n",
    "    np.array([\n",
    "        [0.9, 0.1],\n",
    "        [0.9, 0.1]\n",
    "    ]), # LL\n",
    "    np.array([\n",
    "        [0.9, 0.1],\n",
    "        [0.1, 0.9]\n",
    "    ]), # LR\n",
    "    np.array([\n",
    "        [0.1, 0.9],\n",
    "        [0.9, 0.1]\n",
    "    ]), # RL\n",
    "    np.array([\n",
    "        [0.1, 0.9],\n",
    "        [0.1, 0.9]\n",
    "    ]) # RR\n",
    "]\n",
    "\n",
    "P = np.array(P)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. For each of the polices calculate $V^\\pi$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "r = np.array([[1], [5]]) # the reward matrix\n",
    "gamma = 0.9 # the future discount factor\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "I = np.identity(2)\n",
    "V = []\n",
    "for p in P:\n",
    "    t = I-gamma*p\n",
    "    v = np.linalg.solve(t, r)\n",
    "    V.append(v)\n",
    "\n",
    "V = np.array(V)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "        Policy    State 0    State 1\n0    Left-Left  13.600000  17.600000\n1   Left-Right  22.857143  37.142857\n2   Right-Left  28.837209  31.162791\n3  Right-Right  42.400000  46.400000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Policy</th>\n      <th>State 0</th>\n      <th>State 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Left-Left</td>\n      <td>13.600000</td>\n      <td>17.600000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Left-Right</td>\n      <td>22.857143</td>\n      <td>37.142857</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Right-Left</td>\n      <td>28.837209</td>\n      <td>31.162791</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Right-Right</td>\n      <td>42.400000</td>\n      <td>46.400000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(V.reshape(4, 2))\n",
    "df['Policy'] = ['Left-Left', 'Left-Right', 'Right-Left', 'Right-Right']\n",
    "df = df.rename(columns={0:'State 0', 1: 'State 1'})\n",
    "df = df[['Policy', 'State 0', 'State 1']]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the above table we can conclude that right-right is the best policy."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. Use value iteration to calculate $V^*$\n",
    "#### 4. Use value iteration to improve the policy at each step and eventually find $V^*$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "probs = np.array([[0.9, 0.1],[0.1, 0.9]])\n",
    "\n",
    "def bellman_operator(V):\n",
    "    best_value = deepcopy(V)\n",
    "    greedy_policy = []\n",
    "    for state in [0, 1]:\n",
    "        temp = np.dot(probs, V)\n",
    "        future = r[state, 0] + gamma * temp\n",
    "        policy = np.argmax(future)\n",
    "        greedy_policy.append(policy)\n",
    "        best_value[state] = future[policy]\n",
    "\n",
    "    return greedy_policy, best_value\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "change = float('inf')\n",
    "e = 1e-3\n",
    "V = np.zeros((2, 1))\n",
    "P = [0, 0]\n",
    "while change > e:\n",
    "    P, new_V = bellman_operator(V)\n",
    "    change = np.max(np.abs(new_V-V))\n",
    "    V = new_V"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P* is ['Right', 'Right']\n",
      "V* is [42.39185964 46.39185964]\n"
     ]
    }
   ],
   "source": [
    "P = list(map(lambda x: 'Left' if x==0 else 'Right', P))\n",
    "print('P* is', P)\n",
    "print('V* is', V.flatten())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the V and P are the same as the Q2."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2a860d94",
   "language": "python",
   "display_name": "PyCharm (Reinforcement_Learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}